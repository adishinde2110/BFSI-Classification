{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e12ceab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1968430d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33050, 44)\n",
      "(11017, 44)\n"
     ]
    }
   ],
   "source": [
    "# Importing the datasets for analysis\n",
    "X_df = pd.read_csv('./DS Test/Training/X_train.csv')\n",
    "y_df = pd.read_csv('./DS Test/Training/y_train.csv')\n",
    "X_test_df = pd.read_csv('./DS Test/Test/X_test.csv')\n",
    "print(X_df.shape)\n",
    "print(X_test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c70b558",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df.drop(['Unique_ID'], axis=1, inplace=True)\n",
    "X_test_df.drop(['Unique_ID'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec9ccaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the categorical columns\n",
    "categorical_columns = ['C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8']\n",
    "\n",
    "# Apply one-hot encoding to the training data\n",
    "X_df = pd.get_dummies(X_df, columns=categorical_columns)\n",
    "\n",
    "# Apply one-hot encoding to the test data\n",
    "X_test_df = pd.get_dummies(X_test_df, columns=categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a687cf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate X_df and X_test_df for imputation of missing values and feature scaling\n",
    "concatenated_df = pd.concat([X_df, X_test_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a67a1041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns for mean imputation\n",
    "columns_to_impute = ['N1', 'N2', 'N3', 'N4', 'N5', 'N6', 'N7', 'N8', 'N9', 'N10',\n",
    "                     'N10.1', 'N11', 'N12', 'N14', 'N15', 'N16', 'N17', 'N18', 'N19',\n",
    "                     'N20', 'N21', 'N22', 'N23', 'N24', 'N25', 'N26', 'N27', 'N28',\n",
    "                     'N29', 'N30', 'N31', 'N32', 'N33', 'N34', 'N35']\n",
    "\n",
    "# Apply mean imputation to the selected columns\n",
    "concatenated_df[columns_to_impute] = concatenated_df[columns_to_impute].fillna(concatenated_df[columns_to_impute].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1af20c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with missing values in training dataset: 0\n"
     ]
    }
   ],
   "source": [
    "# Count the number of rows with missing values\n",
    "num_missing_rows = concatenated_df.isnull().any(axis=1).sum()\n",
    "print(\"Number of rows with missing values in training dataset:\", num_missing_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a7eb735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C1_1</th>\n",
       "      <th>C1_2</th>\n",
       "      <th>C1_3</th>\n",
       "      <th>C2_0</th>\n",
       "      <th>C2_1</th>\n",
       "      <th>C2_2</th>\n",
       "      <th>C2_3</th>\n",
       "      <th>C2_4</th>\n",
       "      <th>C2_5</th>\n",
       "      <th>C2_6</th>\n",
       "      <th>...</th>\n",
       "      <th>N26</th>\n",
       "      <th>N27</th>\n",
       "      <th>N28</th>\n",
       "      <th>N29</th>\n",
       "      <th>N30</th>\n",
       "      <th>N31</th>\n",
       "      <th>N32</th>\n",
       "      <th>N33</th>\n",
       "      <th>N34</th>\n",
       "      <th>N35</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.108466e-16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.184997e-16</td>\n",
       "      <td>5.850742e-17</td>\n",
       "      <td>-3.249780e-16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.646694</td>\n",
       "      <td>-0.594962</td>\n",
       "      <td>-1.039876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.108466e-16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.184997e-16</td>\n",
       "      <td>5.850742e-17</td>\n",
       "      <td>-3.249780e-16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.330181</td>\n",
       "      <td>0.203522</td>\n",
       "      <td>-0.355033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.108466e-16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.184997e-16</td>\n",
       "      <td>5.850742e-17</td>\n",
       "      <td>-3.249780e-16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.972319</td>\n",
       "      <td>-0.933772</td>\n",
       "      <td>-0.218065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.108466e-16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.184997e-16</td>\n",
       "      <td>5.850742e-17</td>\n",
       "      <td>-3.249780e-16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.531768</td>\n",
       "      <td>-0.524462</td>\n",
       "      <td>1.014652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.108466e-16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.184997e-16</td>\n",
       "      <td>5.850742e-17</td>\n",
       "      <td>-3.249780e-16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.244452</td>\n",
       "      <td>-0.100547</td>\n",
       "      <td>0.192841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44062</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.108466e-16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.184997e-16</td>\n",
       "      <td>5.850742e-17</td>\n",
       "      <td>-3.249780e-16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.628709</td>\n",
       "      <td>2.518864</td>\n",
       "      <td>0.055872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44063</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.108466e-16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.184997e-16</td>\n",
       "      <td>5.850742e-17</td>\n",
       "      <td>-3.249780e-16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.010628</td>\n",
       "      <td>-1.009695</td>\n",
       "      <td>-1.313813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44064</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.108466e-16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.184997e-16</td>\n",
       "      <td>5.850742e-17</td>\n",
       "      <td>-3.249780e-16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.435996</td>\n",
       "      <td>-0.271080</td>\n",
       "      <td>0.329809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44065</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.304050e+00</td>\n",
       "      <td>-1.251381</td>\n",
       "      <td>-5.757522e-01</td>\n",
       "      <td>-2.140791e-01</td>\n",
       "      <td>-2.123409e+00</td>\n",
       "      <td>-1.609617</td>\n",
       "      <td>-1.132562</td>\n",
       "      <td>-0.972319</td>\n",
       "      <td>-0.970874</td>\n",
       "      <td>0.877684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44066</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.726781e-01</td>\n",
       "      <td>-1.546573</td>\n",
       "      <td>4.760998e+00</td>\n",
       "      <td>-2.140791e-01</td>\n",
       "      <td>-2.159140e+00</td>\n",
       "      <td>-1.016608</td>\n",
       "      <td>2.053125</td>\n",
       "      <td>-0.819084</td>\n",
       "      <td>-0.913261</td>\n",
       "      <td>1.288589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44067 rows × 199 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       C1_1  C1_2  C1_3  C2_0  C2_1  C2_2  C2_3  C2_4  C2_5  C2_6  ...  \\\n",
       "0         1     0     0     1     0     0     0     0     0     0  ...   \n",
       "1         1     0     0     0     0     0     0     1     0     0  ...   \n",
       "2         1     0     0     1     0     0     0     0     0     0  ...   \n",
       "3         1     0     0     0     1     0     0     0     0     0  ...   \n",
       "4         1     0     0     0     1     0     0     0     0     0  ...   \n",
       "...     ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
       "44062     1     0     0     1     0     0     0     0     0     0  ...   \n",
       "44063     1     0     0     1     0     0     0     0     0     0  ...   \n",
       "44064     1     0     0     0     0     0     0     0     0     0  ...   \n",
       "44065     1     0     0     0     1     0     0     0     0     0  ...   \n",
       "44066     1     0     0     0     1     0     0     0     0     0  ...   \n",
       "\n",
       "                N26       N27           N28           N29           N30  \\\n",
       "0     -5.108466e-16  0.000000  1.184997e-16  5.850742e-17 -3.249780e-16   \n",
       "1     -5.108466e-16  0.000000  1.184997e-16  5.850742e-17 -3.249780e-16   \n",
       "2     -5.108466e-16  0.000000  1.184997e-16  5.850742e-17 -3.249780e-16   \n",
       "3     -5.108466e-16  0.000000  1.184997e-16  5.850742e-17 -3.249780e-16   \n",
       "4     -5.108466e-16  0.000000  1.184997e-16  5.850742e-17 -3.249780e-16   \n",
       "...             ...       ...           ...           ...           ...   \n",
       "44062 -5.108466e-16  0.000000  1.184997e-16  5.850742e-17 -3.249780e-16   \n",
       "44063 -5.108466e-16  0.000000  1.184997e-16  5.850742e-17 -3.249780e-16   \n",
       "44064 -5.108466e-16  0.000000  1.184997e-16  5.850742e-17 -3.249780e-16   \n",
       "44065 -1.304050e+00 -1.251381 -5.757522e-01 -2.140791e-01 -2.123409e+00   \n",
       "44066 -8.726781e-01 -1.546573  4.760998e+00 -2.140791e-01 -2.159140e+00   \n",
       "\n",
       "            N31       N32       N33       N34       N35  \n",
       "0      0.000000  0.000000 -0.646694 -0.594962 -1.039876  \n",
       "1      0.000000  0.000000  0.330181  0.203522 -0.355033  \n",
       "2      0.000000  0.000000 -0.972319 -0.933772 -0.218065  \n",
       "3      0.000000  0.000000 -0.531768 -0.524462  1.014652  \n",
       "4      0.000000  0.000000 -0.244452 -0.100547  0.192841  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "44062  0.000000  0.000000  2.628709  2.518864  0.055872  \n",
       "44063  0.000000  0.000000 -1.010628 -1.009695 -1.313813  \n",
       "44064  0.000000  0.000000 -0.435996 -0.271080  0.329809  \n",
       "44065 -1.609617 -1.132562 -0.972319 -0.970874  0.877684  \n",
       "44066 -1.016608  2.053125 -0.819084 -0.913261  1.288589  \n",
       "\n",
       "[44067 rows x 199 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "numerical_columns = concatenated_df.loc[:, 'N1':'N35']\n",
    "\n",
    "# Apply scaling to the numerical columns\n",
    "scaler = StandardScaler()\n",
    "scaled_numerical_columns = scaler.fit_transform(numerical_columns)\n",
    "\n",
    "# Create a new dataframe with the scaled numerical columns\n",
    "df_scaled = pd.DataFrame(scaled_numerical_columns, columns=numerical_columns.columns)\n",
    "\n",
    "# Concatenate the scaled numerical columns with the remaining columns\n",
    "df_scaled = pd.concat([concatenated_df.drop(numerical_columns.columns, axis=1), df_scaled], axis=1)\n",
    "\n",
    "# Print the scaled dataframe\n",
    "display(df_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fb97b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = df_scaled.iloc[:33050].copy()\n",
    "\n",
    "X_test_df = df_scaled.iloc[33050:].copy()\n",
    "# Reset the index of the dataframe\n",
    "X_test_df = X_test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d66749ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    22844\n",
      "1    10206\n",
      "Name: Dependent_Variable, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "class_counts = y_df['Dependent_Variable'].value_counts()\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07e504c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    22844\n",
      "0    22844\n",
      "Name: Dependent_Variable, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Separate the features and target variable\n",
    "y = y_df['Dependent_Variable']\n",
    "\n",
    "# Instantiate the SMOTE object\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Apply SMOTE to the dataset\n",
    "X, y = smote.fit_resample(X_df, y)\n",
    "\n",
    "# Check the class distribution after applying SMOTE\n",
    "class_counts_resampled = pd.Series(y).value_counts()\n",
    "print(class_counts_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "111c2ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  {'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Best AUC-ROC Score:  0.8064223896420503\n",
      "Best Precision Score:  0.8736127264685616\n",
      "Best Recall Score:  0.7165137690130603\n",
      "Best F1-Score:  0.7873007239392853\n",
      "Best Accuracy:  0.806426160012205\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score, roc_auc_score, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Define the RandomForestClassifier\n",
    "lr_classifier = LogisticRegression()\n",
    "\n",
    "# Define the hyperparameters for grid search\n",
    "param_grid = {'penalty': ['l1', 'l2'],\n",
    "              'C': [0.1, 1, 10],\n",
    "              'solver': ['liblinear', 'saga']}\n",
    "\n",
    "# Define the scoring metrics\n",
    "scoring = {\n",
    "    'Precision': make_scorer(precision_score),\n",
    "    'Recall': make_scorer(recall_score),\n",
    "    'F1-Score': make_scorer(f1_score),\n",
    "    'AUC-ROC': make_scorer(roc_auc_score),\n",
    "    'Accuracy': make_scorer(accuracy_score)\n",
    "}\n",
    "\n",
    "# Perform grid search with k-fold cross-validation\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(lr_classifier, param_grid, cv=kfold, scoring=scoring, refit='AUC-ROC')\n",
    "\n",
    "# Fit the model using grid search\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Print the best hyperparameters and the corresponding scores\n",
    "print(\"Best Hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best AUC-ROC Score: \", grid_search.best_score_)\n",
    "print(\"Best Precision Score: \", grid_search.cv_results_['mean_test_Precision'][grid_search.best_index_])\n",
    "print(\"Best Recall Score: \", grid_search.cv_results_['mean_test_Recall'][grid_search.best_index_])\n",
    "print(\"Best F1-Score: \", grid_search.cv_results_['mean_test_F1-Score'][grid_search.best_index_])\n",
    "print(\"Best Accuracy: \", grid_search.cv_results_['mean_test_Accuracy'][grid_search.best_index_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a37e8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  {'n_neighbors': 3, 'weights': 'distance'}\n",
      "Best AUC-ROC Score:  0.6938857723286027\n",
      "Best Precision Score:  0.6271622890368282\n",
      "Best Recall Score:  0.9563324102845592\n",
      "Best F1-Score:  0.7575227461847975\n",
      "Best Accuracy:  0.6938803485849614\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Define the KNeighborsClassifier\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "\n",
    "# Define the hyperparameters for grid search\n",
    "param_grid = {'n_neighbors': [3, 5, 7, 10],\n",
    "              'weights': ['uniform', 'distance']}\n",
    "\n",
    "# Define the scoring metrics\n",
    "scoring = {\n",
    "    'Precision': make_scorer(precision_score),\n",
    "    'Recall': make_scorer(recall_score),\n",
    "    'F1-Score': make_scorer(f1_score),\n",
    "    'AUC-ROC': make_scorer(roc_auc_score),\n",
    "    'Accuracy': make_scorer(accuracy_score)\n",
    "}\n",
    "\n",
    "# Perform grid search with k-fold cross-validation\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(knn_classifier, param_grid, cv=kfold, scoring=scoring, refit='AUC-ROC')\n",
    "\n",
    "# Fit the model using grid search\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Print the best hyperparameters and the corresponding scores\n",
    "print(\"Best Hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best AUC-ROC Score: \", grid_search.best_score_)\n",
    "print(\"Best Precision Score: \", grid_search.cv_results_['mean_test_Precision'][grid_search.best_index_])\n",
    "print(\"Best Recall Score: \", grid_search.cv_results_['mean_test_Recall'][grid_search.best_index_])\n",
    "print(\"Best F1-Score: \", grid_search.cv_results_['mean_test_F1-Score'][grid_search.best_index_])\n",
    "print(\"Best Accuracy: \", grid_search.cv_results_['mean_test_Accuracy'][grid_search.best_index_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3541b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Best AUC-ROC Score:  0.828001467840411\n",
      "Best Precision Score:  0.8426070824859775\n",
      "Best Recall Score:  0.8067219550335005\n",
      "Best F1-Score:  0.8242584469475547\n",
      "Best Accuracy:  0.8279854220737978\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define the RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "# Define the hyperparameters for grid search\n",
    "param_grid = {'n_estimators': [100, 200, 300], \n",
    "              'max_depth': [None, 5, 10], \n",
    "              'min_samples_split': [2, 5, 10]}\n",
    "\n",
    "# Define the scoring metrics\n",
    "scoring = {\n",
    "    'Precision': make_scorer(precision_score),\n",
    "    'Recall': make_scorer(recall_score),\n",
    "    'F1-Score': make_scorer(f1_score),\n",
    "    'AUC-ROC': make_scorer(roc_auc_score),\n",
    "    'Accuracy': make_scorer(accuracy_score)\n",
    "}\n",
    "\n",
    "# Perform grid search with k-fold cross-validation\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(rf_classifier, param_grid, cv=kfold, scoring=scoring, refit='AUC-ROC')\n",
    "\n",
    "# Fit the model using grid search\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Print the best hyperparameters and the corresponding scores\n",
    "print(\"Best Hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best AUC-ROC Score: \", grid_search.best_score_)\n",
    "print(\"Best Precision Score: \", grid_search.cv_results_['mean_test_Precision'][grid_search.best_index_])\n",
    "print(\"Best Recall Score: \", grid_search.cv_results_['mean_test_Recall'][grid_search.best_index_])\n",
    "print(\"Best F1-Score: \", grid_search.cv_results_['mean_test_F1-Score'][grid_search.best_index_])\n",
    "print(\"Best Accuracy: \", grid_search.cv_results_['mean_test_Accuracy'][grid_search.best_index_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d4c4821",
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_estimates = grid_search.predict_proba(X_test_df)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d049a7d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unique_ID</th>\n",
       "      <th>Class_1_Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Candidate_1602</td>\n",
       "      <td>0.525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Candidate_29650</td>\n",
       "      <td>0.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Candidate_31061</td>\n",
       "      <td>0.445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Candidate_5768</td>\n",
       "      <td>0.215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Candidate_27059</td>\n",
       "      <td>0.510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11012</th>\n",
       "      <td>Candidate_7453</td>\n",
       "      <td>0.535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11013</th>\n",
       "      <td>Candidate_38211</td>\n",
       "      <td>0.275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11014</th>\n",
       "      <td>Candidate_25020</td>\n",
       "      <td>0.505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11015</th>\n",
       "      <td>Candidate_44501</td>\n",
       "      <td>0.220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11016</th>\n",
       "      <td>Candidate_49327</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11017 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Unique_ID  Class_1_Probability\n",
       "0       Candidate_1602                0.525\n",
       "1      Candidate_29650                0.400\n",
       "2      Candidate_31061                0.445\n",
       "3       Candidate_5768                0.215\n",
       "4      Candidate_27059                0.510\n",
       "...                ...                  ...\n",
       "11012   Candidate_7453                0.535\n",
       "11013  Candidate_38211                0.275\n",
       "11014  Candidate_25020                0.505\n",
       "11015  Candidate_44501                0.220\n",
       "11016  Candidate_49327                0.250\n",
       "\n",
       "[11017 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_t = pd.read_csv('./DS Test/Test/X_test.csv')\n",
    "y_test_df = pd.DataFrame()\n",
    "y_test_df['Unique_ID'] = X_t['Unique_ID']\n",
    "y_test_df['Class_1_Probability'] = proba_estimates\n",
    "y_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b102d03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unique_ID              2657\n",
       "Class_1_Probability    2657\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_df[y_test_df['Class_1_Probability'] > 0.5].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a608c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test_df.to_csv('./DS Test/Test/final_predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
